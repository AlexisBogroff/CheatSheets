{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods to construct tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long tensors (int/long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tensor of type Long\n",
    "a = torch.tensor([1, 2, 3, 4])  # use integers only\n",
    "a = torch.tensor([1., 2., 3., 4.], dtype=torch.int64)  # LongTensor with int64\n",
    "a = torch.tensor([1., 2., 3., 4.], dtype=torch.int32)  # IntTensor with int32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Float tensors (float/double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build float tensors\n",
    "a = torch.tensor([1, 2, 3], dtype=float)  # DoubleTensor with float64\n",
    "a = torch.tensor([1, 2, 3], dtype=torch.float64)  # DoubleTensor with float64\n",
    "\n",
    "a = torch.tensor([1, 2, 3], dtype=torch.float32)  # FloatTensor with float32\n",
    "b = torch.tensor([1, 2, 3]).float()  # FloatTensor with float32\n",
    "a = torch.FloatTensor([1, 2, 3])  # FloatTensor with float32\n",
    "\n",
    "# transform tensor into float\n",
    "a = a.type(torch.FloatTensor)  # FloatTensor with float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions\n",
    "a.shape\n",
    "a.size()  # idem\n",
    "a.ndimension()  # rank\n",
    "\n",
    "# Types\n",
    "a.type()  # type of Tensor\n",
    "a.dtype  # type of data within Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial shape (3)\n",
    "\n",
    "# Transform in shape (3, 1)\n",
    "a.view(3,1).shape\n",
    "a.view(-1, 1).shape  # Idem\n",
    "\n",
    "# Transform in shape (1, 3)\n",
    "a.view(1, 3).shape\n",
    "a.view(1, -1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform object type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy & Torch\n",
    "# -------------\n",
    "numpy_arr = np.array([1, 2, 3])\n",
    "\n",
    "# Numpy => Torch\n",
    "tensor = torch.from_numpy(numpy_arr)\n",
    "\n",
    "# Torch => Numpy\n",
    "numpy_arr = tensor.numpy()\n",
    "\n",
    "# ps: these are pointers, any change is \n",
    "# repercuted on the other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas & Torch\n",
    "# --------------\n",
    "pd_series = pd.Series([1, 2, 3])\n",
    "\n",
    "# Pandas => Torch\n",
    "tensor = torch.from_numpy(pd_series.values)\n",
    "\n",
    "# Torch => Pandas\n",
    "pd_series = pd.Series(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists & Tensor\n",
    "# --------------\n",
    "\n",
    "# List => Tensor\n",
    "tensor = torch.tensor(dumb_list)\n",
    "\n",
    "# Tensor => List\n",
    "dumb_list = tensor.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple indexing\n",
    "print(tensor)  # (1, 2, 3)\n",
    "tensor[:2] = torch.tensor([100, 200])  # (100, 200, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition, substraction, etc. are element-wise operations\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "z = a + b\n",
    "\n",
    "a + 1  # Broadcasting\n",
    "\n",
    "# Scalar multiplication and division too\n",
    "a*2\n",
    "a/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector multiplication\n",
    "a * b  # element-wise\n",
    "torch.dot(a, b) # Dot product (matrix mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean (must be float)\n",
    "float_tensor = torch.tensor([1, 2, 3]).float()\n",
    "float_tensor.mean()\n",
    "\n",
    "# Max, min\n",
    "tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor in radians\n",
    "tensor_radians = torch.tensor([0, np.pi/2, np.pi])\n",
    "\n",
    "# Sinus\n",
    "tensor_radians.sin()\n",
    "\n",
    "# Generate seq\n",
    "torch.linspace(-2, 2, steps=5)\n",
    "print(torch.linspace(-2, 2, steps=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indexes for True elements\n",
    "bool_tensor = torch.tensor([False, False, True, False, True])\n",
    "bool_tensor.nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differenciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple derivative\n",
    "x = torch.tensor(2., requires_grad=True)\n",
    "y = x**2drop\n",
    "y.backward()  # compute derivative of y\n",
    "x.grad  # evaluate the value of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial derivatives\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "y = torch.tensor(2., requires_grad=True)\n",
    "z = x * y + x**2\n",
    "z.backward()\n",
    "x.grad  # partial derivative of z with regard to x\n",
    "y.grad  # partial derivative of z with regard to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor properties\n",
    "x.data\n",
    "x.grad_fn\n",
    "x.grad\n",
    "x.is_leaf\n",
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowest level implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data\n",
    "x = torch.arange(-3, 3, 0.1).view(-1, 1)\n",
    "y = (-3 * x) + (3 * np.sin(x)) + (.5 * torch.randn(x.size()))\n",
    "\n",
    "# Initialize parameters\n",
    "w = torch.tensor(-10., requires_grad=True)\n",
    "b = torch.tensor(-1., requires_grad=True)\n",
    "\n",
    "# Set hyper-parameters\n",
    "lr = 0.03\n",
    "n_epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return w * x + b\n",
    "\n",
    "def criterion(y_hat, y):\n",
    "    return torch.mean((y_hat - y)**2)\n",
    "\n",
    "list_cost = []\n",
    "for epoch in range(n_epochs):\n",
    "    # predict\n",
    "    y_hat = forward(x)\n",
    "    \n",
    "    # compute cost\n",
    "    loss = criterion(y_hat, y)\n",
    "    \n",
    "    # Optimize with batch gradient descent\n",
    "    loss.backward()  # compute derivatives\n",
    "    w.data = w.data - lr * w.grad.data  # backpropagate\n",
    "    b.data = b.data - lr * b.grad.data\n",
    "    w.grad.data.zero_()  # reset grad for next iter\n",
    "    b.grad.data.zero_()\n",
    "    \n",
    "    list_cost.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x.numpy(), y)  # Plot data\n",
    "plt.plot(x.numpy(), y_hat.data.numpy())  # Plot estimated line\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss evolution (average cost)\n",
    "plt.plot(list_cost)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With manual batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cost = []\n",
    "for epoch in range(n_epochs):\n",
    "    avg_cost_epoch = 0\n",
    "\n",
    "    for x_i, y_i in zip(x, y):  # multiple batches\n",
    "        # predict\n",
    "        y_hat = forward(x_i)\n",
    "        \n",
    "        # compute cost\n",
    "        loss = criterion(y_hat, y_i)\n",
    "        \n",
    "        # Optimize with batch gradient descent\n",
    "        loss.backward()  # compute derivatives\n",
    "        w.data = w.data - lr * w.grad.data  # backpropagate\n",
    "        b.data = b.data - lr * b.grad.data\n",
    "        w.grad.data.zero_()  # reset grad for next iter\n",
    "        b.grad.data.zero_()\n",
    "\n",
    "        avg_cost_epoch += loss.item()\n",
    "\n",
    "    list_cost.append(avg_cost_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With DataLoader (enables mini-batch gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.len = self.x.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Instanciate dataset and loader objects\n",
    "dataset = Dataset(x, y)\n",
    "trainloader = DataLoader(dataset = dataset, batch_size = 4)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x_i, y_i in trainloader:  # Train using batches from loader\n",
    "        y_hat = forward(x_i)\n",
    "        loss = criterion(y_hat, y_i)\n",
    "        loss.backward()\n",
    "        w.data -= lr * w.grad.data\n",
    "        b.data -= lr * b.grad.data\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list_costb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higer-level implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in model (Linear) and optimizer (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from torch import nn, optim\n",
    "\n",
    "# Initialize the linear model\n",
    "model = Linear(in_features=1, out_features=1) # Slope (w) and bias (b) are randomly initialized\n",
    "# Inisitalize the SGD optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x_i, y_i in trainloader:\n",
    "        y_hat = model(x_i)\n",
    "        loss = criterion(y_hat, y_i)\n",
    "        optimizer = zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model/optimizer parameters' (weights) info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameters names and values\n",
    "print('\\n', model.state_dict())\n",
    "\n",
    "# Get parameters' name only\n",
    "print(*model.state_dict())\n",
    "print(model.state_dict().keys())\n",
    "\n",
    "# Get parameters' values only (+ requires_grad info)\n",
    "print(list(model.parameters())[0])  # W\n",
    "print(list(model.parameters())[1])  # bias\n",
    "\n",
    "# Get parameters' value distinctly\n",
    "model.state_dict()['linear.weight'].data[0]\n",
    "model.state_dict()['linear.bias'].data[0]\n",
    "\n",
    "\n",
    "# Change weights' value\n",
    "model.state_dict()['linear.weight'][0] = 1.\n",
    "model.state_dict()['linear.bias'][0] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customize model (linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(LR, self).__init__()\n",
    "        self.linear = nn.Linear(in_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "# Instanciate model\n",
    "model = LR(2, 1)\n",
    "y_hat = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowest level implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.arange(-100, 100, 0.1).view(-1, 1)  # outputs of linear regression\n",
    "\n",
    "# Low level usage\n",
    "sign = nn.Sigmoid()\n",
    "y_hat = sign(z)\n",
    "\n",
    "# Higher level\n",
    "y_hat = torch.sigmoid(z)\n",
    "\n",
    "plt.plot(z, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher level implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regr(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(logistic_regr, self).__init__()\n",
    "        self.linear = nn.Linear(in_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear(x))\n",
    "        return x\n",
    "\n",
    "model = logistic_regr(1, 1)\n",
    "y_hat = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self implemented\n",
    "def criterion(y_hat, y):\n",
    "    return -1 * torch.mean(y * torch.log(y_hat) + (1 - y) * torch.log(1 - y_hat))\n",
    "\n",
    "# Built-in\n",
    "criterion = nn.BCELoss()  # for binary classification, input must be shape Nx1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowest level implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is exactly the same than a Linear Regression implementation\n",
    "# Difference: function call with input value out_size > 1.\n",
    "class Softmax(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(Softmax, self).__init__()\n",
    "        self.linear = nn.Linear(in_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "x = torch.tensor([[1., 3.]])\n",
    "model = Softmax(2, 3)\n",
    "z = model(x)\n",
    "_, y_hat = z.max(1)  # 1 for first dimension (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher level implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with MINST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch import nn, optim\n",
    "\n",
    "# Load data\n",
    "dataset_train = dsets.MNIST(root = './data', train = True, download = True, transform = transforms.ToTensor())\n",
    "dataset_val = dsets.MNIST(root = './data', train = False, download = True, transform = transforms.ToTensor())\n",
    "\n",
    "# Constants\n",
    "n_class = 10\n",
    "img_size = 28 * 28\n",
    "batch_size_train = 100\n",
    "batch_size_val = 5000\n",
    "n_epochs = 1\n",
    "lr = 0.01\n",
    "n_val = len(dataset_val)\n",
    "\n",
    "# Instanciation time\n",
    "model = Softmax(img_size, n_class)\n",
    "criterion = nn.CrossEntropyLoss()  # input must be shape N (not Nx1)\n",
    "optimizer = optim.SGD(model.parameters(), lr = lr)\n",
    "loader_train = torch.utils.data.DataLoader(dataset = dataset_train, batch_size = batch_size_train)\n",
    "loader_val = torch.utils.data.DataLoader(dataset = dataset_val, batch_size = batch_size_val)\n",
    "\n",
    "# Training time\n",
    "accuracy_list = []\n",
    "for i_epoch in range(n_epochs):\n",
    "    for i_batch, (x, y) in enumerate(loader_train):\n",
    "        optimizer.zero_grad()\n",
    "        z = model(x.view(-1, img_size))\n",
    "        loss = criterion(z, y)  # z is provided, rather than y_hat\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % 100 == 0:\n",
    "            print(\"Epoch {n_epoch} | batch {n_batch} | loss {loss}\".format(n_epoch = i_epoch, n_batch = i_batch, loss = round(loss.item(), 3)))\n",
    "    \n",
    "    correct = 0\n",
    "    for x, y in loader_val:\n",
    "        z = model(x.view(-1, img_size))\n",
    "        _, y_hat = torch.max(z.data, 1)\n",
    "        correct += (y_hat == y).sum().item()\n",
    "\n",
    "    accuracy = correct / n_val\n",
    "    accuracy_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracy_list)\n",
    "#plt.imshow(dataset_train[0][0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(1,1), nn.Sigmoid())\n",
    "y_hat = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowest level implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add \"hidden_size\" compared to previous models\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(0)\n",
    "model = Net(3, 2, 1)\n",
    "x = torch.tensor([0., 1., 4.])\n",
    "\n",
    "y_hat = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher level implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 2\n",
    "in_size = 1\n",
    "out_size = 1\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_size, n_hidden),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(n_hidden, out_size),\n",
    "    torch.nn.Sigmoid())\n",
    "\n",
    "X = torch.arange(-30, 30, 1).view(-1, 1).type(torch.FloatTensor)\n",
    "Y = torch.zeros(X.shape[0])\n",
    "Y[(X[:, 0] > -10) & (X[:, 0] < 10)] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with MINST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "from torch import nn, optim\n",
    "\n",
    "# Load data\n",
    "dataset_train = dsets.MNIST(root = './data', train = True, download = True, transform = transforms.ToTensor())\n",
    "dataset_val = dsets.MNIST(root = './data', train = False, download = True, transform = transforms.ToTensor())\n",
    "\n",
    "# Instanciate data loaders\n",
    "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size = 2000)\n",
    "loader_val = torch.utils.data.DataLoader(dataset_val, batch_size = 5000)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple hidden layers built easily\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "\n",
    "        for input_size, output_size in zip(layers, layers[1:]):\n",
    "            self.hidden.append(nn.Linear(input_size, output_size))\n",
    "\n",
    "    def forward(self, activation):\n",
    "        for i_layer, linear_transform in enumerate(self.hidden_layers):\n",
    "            if i_layer < len(self.hidden_layers) - 1:\n",
    "                activation = torch.relu(linear_transform(activation))\n",
    "            else:\n",
    "                activation = linear_transform(activation)\n",
    "        return activation\n",
    "\n",
    "layers = [2, 3, 4, 3]\n",
    "model = Net(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_size, h1, h2, h3, out_size, p=0):\n",
    "        super(Net, self).__init__()\n",
    "        self.drop = nn.Dropout(p=p)\n",
    "        self.linear_in = nn.Linear(in_size, h1)\n",
    "        self.linear_h1 = nn.Linear(h1, h2)\n",
    "        self.linear_h2 = nn.Linear(h2, h3)\n",
    "        self.linear_out = nn.Linear(h3, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear_in(x))\n",
    "        x = self.drop(x)\n",
    "        x = torch.relu(self.linear_h1(x))\n",
    "        x = self.drop(x)\n",
    "        x = torch.relu(self.linear_h2(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.linear_out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters' Initialization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all methods (but ReLu)\n",
    "torch.nn.init.xavier_uniform_(linear.weight)\n",
    "# Initialization for ReLu (\"H-e method\")\n",
    "torch.nn.init.kaiming_uniform_(linear.weight, nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetBatchNorm(nn.Module):\n",
    "    def __init__(self, in_size, h_size, out_size):\n",
    "        super(NetBatchNorm, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_size, h_size)\n",
    "        self.linear2 = nn.Linear(h_size, out_size)\n",
    "\n",
    "        self.batch1 = nn.BatchNorm1d(h_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.batch1(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[[0.0000, 0.0190, 0.0000],\n          [0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000]]]], grad_fn=<ReluBackward0>)"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=2, padding=1)\n",
    "image = torch.zeros(1, 1, 5, 5)\n",
    "image[0, 0, :, 2] = 1\n",
    "\n",
    "# Apply convolution\n",
    "z = conv(image)\n",
    "\n",
    "# Apply activation on activ. map\n",
    "A = torch.relu(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Pooling\n",
    "max = torch.nn.MaxPool2d(kernel_size=2, stride=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set weights' value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x128affe48>"
     },
     "metadata": {},
     "execution_count": 88
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"252.317344pt\" version=\"1.1\" viewBox=\"0 0 271.074375 252.317344\" width=\"271.074375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 252.317344 \nL 271.074375 252.317344 \nL 271.074375 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 38.482813 228.439219 \nL 255.922813 228.439219 \nL 255.922813 10.999219 \nL 38.482813 10.999219 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p7c3a678ba8)\">\n    <image height=\"218\" id=\"imageab1f27f7b0\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"38.482813\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAABHNCSVQICAgIfAhkiAAAAqlJREFUeJzt1UERQWEAhVHMi0ADIeghg1BSaGGrhY0GxpDA9vvfG+ckuJtv7vr92H9W/HS4n0ZPmL3XdTd6wuxtRg+AfyA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg8A0egDLt73cRk+YPY8GAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEJhGD2D5nufj6Amz59EgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDwBeL/grbnL+KZQAAAABJRU5ErkJggg==\" y=\"-10.439219\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m79fc01db6b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m79fc01db6b\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −0.5 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(26.341406 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"74.722813\" xlink:href=\"#m79fc01db6b\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.0 -->\n      <g transform=\"translate(66.77125 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"110.962812\" xlink:href=\"#m79fc01db6b\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.5 -->\n      <g transform=\"translate(103.01125 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.202812\" xlink:href=\"#m79fc01db6b\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(139.25125 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"183.442813\" xlink:href=\"#m79fc01db6b\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 1.5 -->\n      <g transform=\"translate(175.49125 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"219.682812\" xlink:href=\"#m79fc01db6b\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2.0 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(211.73125 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"255.922812\" xlink:href=\"#m79fc01db6b\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 2.5 -->\n      <g transform=\"translate(247.97125 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m1f2e1b7fcf\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m1f2e1b7fcf\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- −0.5 -->\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m1f2e1b7fcf\" y=\"47.239219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.0 -->\n      <g transform=\"translate(15.579688 51.038437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m1f2e1b7fcf\" y=\"83.479219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.5 -->\n      <g transform=\"translate(15.579688 87.278437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m1f2e1b7fcf\" y=\"119.719219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.0 -->\n      <g transform=\"translate(15.579688 123.518437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m1f2e1b7fcf\" y=\"155.959219\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.5 -->\n      <g transform=\"translate(15.579688 159.758437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m1f2e1b7fcf\" y=\"192.199219\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 2.0 -->\n      <g transform=\"translate(15.579688 195.998437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m1f2e1b7fcf\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 2.5 -->\n      <g transform=\"translate(15.579688 232.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 38.482813 228.439219 \nL 38.482813 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 255.922813 228.439219 \nL 255.922813 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 38.482813 228.439219 \nL 255.922812 228.439219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 38.482813 10.999219 \nL 255.922812 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7c3a678ba8\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"38.482813\" y=\"10.999219\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Instanciate a multiple (3) output convolution layer\n",
    "conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "\n",
    "# Set weights' value\n",
    "Gx = torch.tensor([[1., 0., -1.], [1., 0., -2.], [1., 0., -1.]])\n",
    "Gy = torch.tensor([[1., 2., -1.], [0., 0., 0.], [-1., -2., -1.]])\n",
    "conv1.state_dict()['weight'][0][0] = Gx\n",
    "conv1.state_dict()['weight'][1][0] = Gy\n",
    "conv1.state_dict()['weight'][2][0] = torch.ones(3, 3)/6\n",
    "conv1.state_dict()['bias'][:] = torch.tensor([0., 0., 0.])\n",
    "\n",
    "img1 = torch.zeros(1, 1, 5, 5)\n",
    "img1[0, 0, :, 2] = 1\n",
    "z = conv1(img1)\n",
    "\n",
    "plt.imshow(Gx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets loadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)  # Define parameters' initialization value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "dataset = datasets.MNIST(root = './data', train = False, download = True, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_misclassified = 0\n",
    "for i, (x, y) in enumerate(dataset_val):\n",
    "    z = model(x.reshape(-1, 28 * 28))\n",
    "    y_hat_proba, y_hat_idx = torch.max(z, 1)\n",
    "    if y_hat_idx != y:\n",
    "        #show_data(x)\n",
    "        print(i)\n",
    "        n_misclassified += 1\n",
    "    if n_misclassified >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = data_monitoring(db = dataset_val, model = model)\n",
    "n_misclassified, dic_missclasified = monitor.get_misclassified_samples(sample_size_flatten=784, plot=True, plot_shape=(28, 28))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36264bitpytorchvirtualenvb2c3f00e98dc48dba8e2131dc30ce6c5",
   "display_name": "Python 3.6.2 64-bit ('pytorch': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}